# ğŸ¤– JARVIS â€“ Local Voice AI Assistant

JARVIS is a **fully local, offline AI assistant** built using **Ollama**, **Python**, and **qwen3:0.6b**.
It supports **conversation memory**, **voice input**, **voice output**, and a clean **agent-style architecture**
designed for stability on **Windows**.

No cloud APIs. No subscriptions. Full control.

---

## âœ¨ Features

- ğŸ§  Local LLM via **Ollama**
- ğŸ’¬ Conversational continuity (session memory)
- ğŸ—£ï¸ Voice input (Speech â†’ Text) using **Whisper**
- ğŸ”Š Voice output (Text â†’ Speech) using **Windows SAPI**
- ğŸ¤ Continuous voice mode
- âŒ¨ï¸ Text fallback mode
- ğŸ§¾ Explicit memory commands
- ğŸšª Voice-based exit with spoken farewell
- ğŸ–¥ï¸ Windows-first, offline, CPU-friendly

---

## ğŸ§± Project Structure

```
JARVIS/
â”œâ”€â”€ jarvis.py          # CLI entry point (agent loop, voice mode, control)
â”œâ”€â”€ brain.py           # LLM interaction (Ollama requests)
â”œâ”€â”€ memory.py          # In-session conversation memory
â”œâ”€â”€ context.py         # System persona & instructions (JARVIS)
â”œâ”€â”€ model_loader.py    # Model readiness & warm-up checks
â”œâ”€â”€ voice.py           # Voice input (STT) and output (TTS)
â”œâ”€â”€ config.py          # Central configuration
â””â”€â”€ Modelfile          # Custom Ollama model definition
```

---

## ğŸ§  Model Used

- **Base model:** qwen3:0.6b
- **Runtime:** Ollama
- **Why this model?**
  - Fast startup
  - Low memory usage
  - Good conversational quality
  - Ideal for local assistants

---

## âš™ï¸ Requirements

### Software
- Windows 10 / 11
- Python 3.10+
- Ollama installed and running

### Python Packages
```
pip install requests sounddevice numpy scipy openai-whisper pywin32
```

### Ollama
```
ollama pull qwen3:0.6b
```

---

## ğŸ› ï¸ Setup

### 1ï¸âƒ£ Create Custom JARVIS Model

Example Modelfile:
```
FROM qwen3:0.6b

SYSTEM """
You are JARVIS, an advanced AI assistant.
Always be concise, professional, and address the user as Sir.
Do not reveal internal reasoning.
"""
```

Create the model:
```
ollama create jarvis -f Modelfile
```

---

### 2ï¸âƒ£ Configure the Project

Edit `config.py`:
```
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "jarvis"
ASSISTANT_NAME = "JARVIS"
USER_TITLE = "Sir"
```

---

### 3ï¸âƒ£ Run JARVIS

```
python jarvis.py
```

---

## ğŸ—£ï¸ Voice Commands

### Enable voice mode
```
voice on
```

### Exit using voice
Say:
```
exit
```

JARVIS will speak a farewell and exit cleanly.

---

## ğŸ§¾ Memory Commands

Handled locally (not via LLM):

- `show memory`
- `clear memory`

---

## ğŸ§  Design Principles

- Control logic never sent to the LLM
- Voice is an interface layer, not intelligence
- Explicit state management
- Windows-stable dependencies only
- No streaming to avoid hangs
- Fail-safe UX (no infinite hot-mic loops)

---

## ğŸŸ¢ Completed Phases

### Phase 1 â€“ Core Assistant
- Local LLM
- Persona enforcement
- Stable CLI
- Model warm-up handling

### Phase 2 â€“ Memory & Voice
- Conversation continuity
- Explicit memory control
- Voice input (Whisper)
- Voice output (Windows SAPI)
- Continuous voice mode
- Guaranteed voice exit

---

## ğŸš€ Future Enhancements

- Wake word (â€œHey JARVISâ€)
- Push-to-talk hotkey
- Persistent memory (SQLite)
- System tools
- GUI (Tkinter / Web UI)
- Background service mode

---

## ğŸ“œ License

For learning and personal use.
